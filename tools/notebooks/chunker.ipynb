{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\r\n",
    "import json\r\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../../meta\\beatsaber\n",
      "['beatsaber_0.json', 'beatsaber_1.json', 'beatsaber_10.json', 'beatsaber_11.json', 'beatsaber_2.json', 'beatsaber_3.json', 'beatsaber_4.json', 'beatsaber_5.json', 'beatsaber_6.json', 'beatsaber_7.json', 'beatsaber_8.json', 'beatsaber_9.json']\n",
      "../../meta\\boxvr\n",
      "['boxvr_0.json', 'boxvr_1.json', 'boxvr_2.json', 'boxvr_3.json', 'boxvr_4.json', 'boxvr_5.json']\n",
      "../../meta\\generic\n",
      "['generic_0.json', 'generic_1.json', 'generic_2.json']\n",
      "../../meta\\jobsimulator\n",
      "['jobsimulator_0.json', 'jobsimulator_1.json', 'jobsimulator_10.json', 'jobsimulator_11.json', 'jobsimulator_12.json', 'jobsimulator_13.json', 'jobsimulator_14.json', 'jobsimulator_2.json', 'jobsimulator_3.json', 'jobsimulator_4.json', 'jobsimulator_5.json', 'jobsimulator_6.json', 'jobsimulator_7.json', 'jobsimulator_8.json', 'jobsimulator_9.json']\n",
      "../../meta\\spacepiratetrainer\n",
      "['spacepiratetrainer_0.json', 'spacepiratetrainer_1.json', 'spacepiratetrainer_2.json', 'spacepiratetrainer_3.json', 'spacepiratetrainer_4.json', 'spacepiratetrainer_5.json', 'spacepiratetrainer_6.json', 'spacepiratetrainer_7.json', 'spacepiratetrainer_8.json', 'spacepiratetrainer_9.json']\n"
     ]
    }
   ],
   "source": [
    "dataset_path = '../../'\r\n",
    "\r\n",
    "meta_root_path = os.path.join(dataset_root, 'meta')\r\n",
    "game_ids = next(os.walk(meta_root))[1]\r\n",
    "\r\n",
    "for game_id in game_ids:\r\n",
    "    meta_game_root_path = os.path.join(meta_root_path, game_id)\r\n",
    "    game_samples = next(os.walk(meta_game_root_path))[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['train_300', 'train_300', 'train_300', 'train_300', 'train_300', 'train_300', 'train_300', 'test_300', 'test_300', 'train_300', 'val_300', 'test_300', 'val_300', 'train_300', 'val_300', 'train_300', 'val_300', 'train_300', 'train_300', 'val_300', 'train_300', 'test_300', 'train_300', 'train_300', 'train_300', 'train_300', 'train_300', 'val_186', 'train_81', 'test_64']\n"
     ]
    }
   ],
   "source": [
    "import random\r\n",
    "\r\n",
    "def chunks_per_ratio(num_frames, split, minC, maxC):\r\n",
    "    f = int(num_frames * split)\r\n",
    "    c = int(f / maxC)\r\n",
    "    if f - (c * maxC) > minC:\r\n",
    "        c += 1\r\n",
    "\r\n",
    "    return f, c\r\n",
    "\r\n",
    "def chunk_frames(num_frames, split_test = 0.15, split_validation = 0.20, min_chunk = 30, max_chunk = 300):\r\n",
    "    num_chunks = int(num_frames/max_chunk)\r\n",
    "    tot_frames = num_chunks * max_chunk\r\n",
    "    if num_frames - tot_frames >= min_chunk:\r\n",
    "        num_chunks += 1\r\n",
    "        tot_frames = num_frames\r\n",
    "\r\n",
    "    frames = [0,0,0]\r\n",
    "    prefix = ['train_','val_', 'test_']\r\n",
    "    frames[0], num_train_chunks = chunks_per_ratio(num_frames, 1.0 - (split_test + split_validation), min_chunk, max_chunk)\r\n",
    "    frames[1], num_val_chunks = chunks_per_ratio(num_frames, split_validation, min_chunk, max_chunk)\r\n",
    "    frames[2], num_test_chunks = chunks_per_ratio(num_frames, split_test, min_chunk, max_chunk)\r\n",
    "    tot_frames = frames[0] + frames[1] + frames[2]\r\n",
    "\r\n",
    "    rnd_distribution = [0] * num_train_chunks\r\n",
    "    rnd_distribution.extend([1]* num_val_chunks)\r\n",
    "    rnd_distribution.extend([2]* num_test_chunks)\r\n",
    "    random.shuffle(rnd_distribution)\r\n",
    "\r\n",
    "    chunk_out = list()\r\n",
    "    for rnd_id in rnd_distribution:\r\n",
    "        chunkSize = max_chunk\r\n",
    "        if frames[rnd_id] < chunkSize:\r\n",
    "            chunkSize = frames[rnd_id]\r\n",
    "        frames[rnd_id] -= chunkSize\r\n",
    "        \r\n",
    "        chunk_out.append(f'{prefix[rnd_id]}{chunkSize}')\r\n",
    "\r\n",
    "    return chunk_out\r\n",
    "\r\n",
    "def split_source_file(bvh_source, split_key, out_path):\r\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.6 64-bit",
   "name": "python376jvsc74a57bd00600588c3b5f4418cbe7b5ebc6825b479f3bc010269d8b60d75058cdd010adfe"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "orig_nbformat": 2
 },
 "nbformat": 4,
 "nbformat_minor": 2
}